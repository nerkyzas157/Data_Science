{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used \"pip install -r requirments.txt\" command in .venv terminal\n",
    "\n",
    "# Imported libraries for the project\n",
    "import tensorflow\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Loaded built-in MNIST handwriting dataset\n",
    "mnist = tensorflow.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Pixel values have to be normalized by division\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Built a neural network model from Conv2D and Dense\n",
    "model = Sequential(\n",
    "    [\n",
    "        Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Created compiler to tell the model how to learn\n",
    "model.compile(\n",
    "    optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Training time!\n",
    "model.fit(train_images[..., tensorflow.newaxis], train_labels, epochs=5, batch_size=64)\n",
    "\n",
    "# Evaluation of the results\n",
    "test_loss, test_accuracy = model.evaluate(\n",
    "    test_images[..., tensorflow.newaxis], test_labels\n",
    ")\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "\n",
    "# Finally we can make predictions with on new images\n",
    "predictions = model.predict(test_images[..., tensorflow.newaxis])\n",
    "\n",
    "# Choose 5 random images for vizualization of the model results\n",
    "num_images = 5\n",
    "random_indices = np.random.choice(len(test_images), num_images, replace=False)\n",
    "sample_images = test_images[random_indices]\n",
    "sample_labels = test_labels[random_indices]\n",
    "\n",
    "# Use trained model to predict labels for the sample images\n",
    "sample_predictions = model.predict(sample_images[..., tensorflow.newaxis])\n",
    "predicted_labels = np.argmax(sample_predictions, axis=1)\n",
    "\n",
    "# Created visuals for the sample images along with their predicted labels\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(num_images):\n",
    "    plt.subplot(1, num_images, i + 1)\n",
    "    plt.imshow(sample_images[i], cmap=\"gray\")\n",
    "    plt.title(f\"Predicted: {predicted_labels[i]}\\nActual: {sample_labels[i]}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Test with random digit images from the web\n",
    "from PIL import Image\n",
    "\n",
    "# Defined path\n",
    "image_paths = [\n",
    "    \"C:/Users/Neriukas/Desktop/Projektai/HDR/test1.png\",\n",
    "    \"C:/Users/Neriukas/Desktop/Projektai/HDR/test0.png\",\n",
    "    \"C:/Users/Neriukas/Desktop/Projektai/HDR/test2.png\",\n",
    "    \"C:/Users/Neriukas/Desktop/Projektai/HDR/test3.jpg\",\n",
    "]\n",
    "\n",
    "# Set preprocessing settings\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"L\")  # Convert to grayscale\n",
    "    image = image.resize((28, 28))  # Resize to 28x28 pixels\n",
    "    image = np.array(image) / 255.0  # Normalize pixel values\n",
    "    return image\n",
    "\n",
    "# Preprocessed images and set labels\n",
    "images = [preprocess_image(image_path) for image_path in image_paths]\n",
    "labels = [7, 1, 7, 6]\n",
    "\n",
    "# Converted into arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Expanded dimentions\n",
    "images = np.expand_dims(images, axis=-1)\n",
    "\n",
    "# Model had to be trained with new data\n",
    "model.fit(images, [labels], epochs=10)\n",
    "test_loss, test_accuracy = model.evaluate(images, [labels])\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "\n",
    "# Compiled the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Evaluated performance\n",
    "test_loss, test_accuracy = model.evaluate(images, labels)\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "\n",
    "# Made predictions\n",
    "predictions = model.predict(images)\n",
    "\n",
    "# Vizualized the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(len(image_paths)):\n",
    "    plt.subplot(1, len(image_paths), i + 1)\n",
    "    plt.imshow(images[i].squeeze(), cmap=\"gray\")\n",
    "    plt.title(f\"Predicted: {np.argmax(predictions[i])}\\nActual: {labels[i]}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
